{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarciaLnk/LlamaRec/blob/main/demo_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGV1cOGtdH_"
      },
      "source": [
        "# LlamaRec Demo Notebook\n",
        "\n",
        "This notebook is provided to allow users to deploy the LlamaRec demo on a free GPU-enabled provider like Google Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKcZRx4tdIB"
      },
      "source": [
        "## Install mamba on Colab (run individually)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCz6dBnutdIC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    %pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiPZ9lxtdIC"
      },
      "source": [
        "## Download demo files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31x65p4AtdID"
      },
      "outputs": [],
      "source": [
        "!wget https://files.garcialnk.com/llamarec-demo.zip -O ./demo.zip\n",
        "!unzip ./demo.zip\n",
        "%rm ./demo.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh1zSOg9tdID"
      },
      "source": [
        "## Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAwPRYXltdIE"
      },
      "outputs": [],
      "source": [
        "!mamba install -y streamlit pytorch pytorch-cuda=12.1 transformers peft filelock whoosh -c pytorch -c nvidia\n",
        "%pip install --no-deps bitsandbytes triton\n",
        "%pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQYgdSTtdIG"
      },
      "source": [
        "## Forward port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOrsNofQtdIG"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x ./cloudflared-linux-amd64\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_process(cmd):\n",
        "    with open('output.txt', 'w') as f:\n",
        "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "        if process.stdout:\n",
        "            for line in iter(process.stdout.readline, b''):\n",
        "                f.write(line.decode())\n",
        "                f.flush()\n",
        "\n",
        "cmd = [\"./cloudflared-linux-amd64\", \"tunnel\", \"--url\", \"http://localhost:8501\"]\n",
        "thread = threading.Thread(target=run_process, args=(cmd,))\n",
        "thread.start()\n",
        "\n",
        "!sleep 5\n",
        "!grep -o 'https://.*\\.trycloudflare.com' output.txt | head -n 1 | xargs -I {} echo \"Your tunnel url {}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXDV-xUJtdIG"
      },
      "source": [
        "## Start demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjC_TTwltdIH"
      },
      "outputs": [],
      "source": [
        "%cd ./demo\n",
        "!streamlit run ./app.py --server.address=localhost --server.port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
